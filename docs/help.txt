
NOTE: There is no book.csv file, as it is big so, please add it in the project
root folder before running the code.


Task 1 — Full Setup & Execution Guide
======================================
Run T3 Master-Only with 1 Master + 3 Workers
(Just runs once to show output — no timing recorded.)

Step 1 — Start Docker Cluster

Make sure Docker Desktop is running, then open your terminal and start all containers:
docker compose up -d
This launches:
•	mpi_master (the coordinator)
•	mpi_w1, mpi_w2, and mpi_w3 (the 3 workers)
 
Step 2 — Enter the Master Container
docker exec -it mpi_master bash
Now you’re inside the master container as root.
 
Step 3 — Go to the Shared Workspace
cd /workspace
The /workspace folder is mounted from your host so all containers share the same files (code + dataset).
 
Step 4 — Run the T3 Master-Only Program
mpirun -n 4 -f /workspace/hostfile python /workspace/src/q1/t3_master_only.py
Explanation:
•	-n 4 → total 4 processes (1 master + 3 workers)
•	-f /workspace/hostfile → tells MPI which containers to use
•	The master distributes work; workers do the processing.
 
Expected Output Example
{
 'final_answer': 1192657,
 'chunkSizePerThread': [0, 1000000, 1000000, 1000000],
 'answerPerThread': [0, 395814, 397612, 399231],
 'totalTimeTaken': 17.78
}
This confirms your MPI cluster is working — the master coordinates while the 3 workers perform computation.
 
That’s it for Task 1.
Once this runs successfully, you’re ready to move on to Task 2 (analysis) using the timed loops for Q1–Q4.


Part 2 — Analysis (Q1–Q4 with 4→10 Workers)
=============================================
Each section below creates a CSV file with execution times in the results/ folder.
 
Q1 – src/q1/t3_master_only.py
cd /workspace
echo "containers,seconds" > results/q1_times.csv
for n in 4 5 6 7 8 9 10; do
  echo ">>> START n=$n $(date +%T)"
  start=$(date +%s)
  mpirun -n $n -f /workspace/hostfile python /workspace/src/q1/t3_master_only.py > tmp_out.txt 2>&1
  end=$(date +%s)
  elapsed=$((end - start))
  echo ">>> DONE n=$n $(date +%T) (time=${elapsed}s)"
  cat tmp_out.txt
  echo "$n,$elapsed" | tee -a results/q1_times.csv
done
 
Q2 – src/q2/t3q2_master.py
cd /workspace
echo "containers,seconds" > results/q2_times.csv
for n in 4 5 6 7 8 9 10; do
  echo ">>> START n=$n $(date +%T)"
  start=$(date +%s)
  mpirun -n $n -f /workspace/hostfile python /workspace/src/q2/t3q2_master.py > tmp_out.txt 2>&1
  end=$(date +%s)
  elapsed=$((end - start))
  echo ">>> DONE n=$n $(date +%T) (time=${elapsed}s)"
  cat tmp_out.txt
  echo "$n,$elapsed" | tee -a results/q2_times.csv
done
 
Q3 – src/q3/t3q3_master.py
cd /workspace
echo "containers,seconds" > results/q3_times.csv
for n in 4 5 6 7 8 9 10; do
  echo ">>> START n=$n $(date +%T)"
  start=$(date +%s)
  mpirun -n $n -f /workspace/hostfile python /workspace/src/q3/t3q3_master.py > tmp_out.txt 2>&1
  end=$(date +%s)
  elapsed=$((end - start))
  echo ">>> DONE n=$n $(date +%T) (time=${elapsed}s)"
  cat tmp_out.txt
  echo "$n,$elapsed" | tee -a results/q3_times.csv
done
 
Q4 – src/q4/t3q4_master.py
cd /workspace
echo "containers,seconds" > results/q4_times.csv
for n in 4 5 6 7 8 9 10; do
  echo ">>> START n=$n $(date +%T)"
  start=$(date +%s)
  mpirun -n $n -f /workspace/hostfile python /workspace/src/q4/t3q4_master.py > tmp_out.txt 2>&1
  end=$(date +%s)
  elapsed=$((end - start))
  echo ">>> DONE n=$n $(date +%T) (time=${elapsed}s)"
  cat tmp_out.txt
  echo "$n,$elapsed" | tee -a results/q4_times.csv
done
 
How to Run Everything
1.	Make sure Docker Desktop is running.
2.	Start the cluster: docker compose up -d
3.	Enter the master: docker exec -it mpi_master bash
4.	Paste and run the command block for each section (Q1–Q4).
 
Outputs Created
•	results/q1_times.csv, results/q2_times.csv, results/q3_times.csv, results/q4_times.csv
	→ contain container count vs time
•	You can use these for your MPI Execution Analysis graph.

That's everything you need for your report and demo — paste as-is into your terminal inside mpi_master.

